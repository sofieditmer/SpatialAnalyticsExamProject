____________________________________________________
__SPATIAL ANALYSIS SCRIPT__
Course: Spatial Analytics Exam | Aarhus University
Auhtors: Mie Arnau Martinez & Sofie Ditmer
____________________________________________________

__SCRIPT CONTENT__: This script contains a spatial analysis of the UK election spatial data. The spatial analysis includes the creation of basic visualizations that are used as stepping stones for creating cartograms, performing spatial autocorrelation tests, and addressing the Modifiable Areal Unit Problem (MAUP). 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

-------- ## __LOAD REQUIRED PACKAGES__ ## --------

```{r packages, include = FALSE}
# Install and load pacman for package management
install.packages("pacman")
library(pacman)

# Install/load necessary packages with p_load
p_load(tidyverse,
       sf,
       tmap,
       rgdal,
       spdep,
       maptools,
       cartogram)
```

-------- ## __LOAD PREPROCESSED DATA__ ## --------

First we need to load the preprocessed data from the ```Preprocessing.Rmd``` script. This is a shapefile that contains all the necessary data for the spatial analysis. 

```{r load data, include=TRUE}
# Load shapefile
data <- st_read("../data/space_data.shp")

# Change column names to be more interpretable
data <- data %>% 
  rename(
    perc_votes_conservative = prc_vts_c,
    perc_votes_labour = prc_vts_l,
    electorates = Electrt,
    county = County,
    population_count = popultn,
    average_age = averg_g,
    average_income = men_ncm,
    perc_white_population = prcnt__,
    urban_rural_class = Clssfct,
    n_pubs = pub_cnt, 
    pubs_per_inhabitant = pbs_pr_,
    constituency_area = area,
    population_density = pp_dnst,
    constituency = Cnsttnc,
    )

# Inspect the data to make sure everything looks decent
head(data)
```

-------- ## __BASIC VISUALIZATIONS__ ## --------

To start off the spatial analysis of the preprocessed data, we start by producing three plots to get an overview of the data.

__The following plots are produced:__
    1. Constitency population
    2. Conservative vote share for each constituency
    3. Labour vote share for each constituency
    4. Constituencies classified as either rural or urban

PLOTTING CONSTITUENCY *POPULATION*
```{r plotting constituency population}
# Plot constituency population
tm_shape(data) + 
  tm_polygons(col = "population_count", title = "Population Count") +
  tm_layout(main.title = "Constituencies by population", 
            main.title.size = 0.9)
```

PLOTTING *CONSERVATIVE* VOTE SHARE PER CONSTITUENCY
```{r plotting Conservative vote share, include=TRUE}
tm_shape(data) + 
  tm_polygons(col = "perc_votes_conservative", title = "Conservative Vote Share (%)", palette = "Blues") +
  tm_layout(main.title = "Conservative Vote Share per Constituency", 
            main.title.size = 0.9)
```

PLOTTING *LABOUR VOTE* SHARE PER CONSTITUENCY
```{r plotting Labour vote share, include=TRUE}
tm_shape(data) + 
  tm_polygons(col = "perc_votes_labour", title = "Labour Vote Share (%)", palette = "Reds") +
  tm_layout(main.title = "Labour Vote Share per Constituency", 
            main.title.size = 0.9)
```

PLOTTING *URBAN/RURAL* CONSTITUENCY CLASSIFICATION
```{r plotting rural/urban classification, include=TRUE}
tm_shape(data) + 
  tm_polygons("urban_rural_class", title = "Urban/Rural Classification") +
  tm_layout(main.title = "Urban/Rural Classification of Constituencies", 
            main.title.size = 0.9)
```

__CONCLUSION__
From these basic visualizations of the English parliamentary constituencies and the 2019 election data we can gain a sense of the distribution of Conservative and Labour votes in relation to urban and rural areas. There is a tendency for urban areas to favor the Labour party while more rural areas have favored the Conservative party. However, there is a clear problem with some constituencies carrying more visual weight than others. To solve this problem we create cartograms. 

-------- ## __CARTOGRAMS__ ## --------

When mapping parliamentary constituencies that are defined to have an equal number of electorates, it becomes clear that the larger constituencies carry more visual significance compared to smaller constituencies even though they reprsent an equal number of voters. E.g. the city of London is divided into several small constituencies because of its high population density, and these constituencies are easy to overlook in a map. 
In order to correct for this visual imbalance, we create cartograms that modify the sizes of the constituencies to be proportional to the number of electorates. This means that rural constituencies with a low population density will be contracted in size to be proportional to their number of electorates while high density urban constituencies will be expanded. The placement of the constituencies is however not altered, which means that constituencies will remain in roughly the same place relative to one another. 
It is important to note that the cartograms produced below are not geographically correct, rather they are simulated. In other words, the cartograms are distorted spatial representations of the English parliamentary constituencies relative to the number of eligible voters in each constituency. 

__CARTOGRAM 1:__ SCALING CONSTITUENCIY AREA TO *TOTAL NUMBER OF ELECTORATES* IN 2019 
We start by making a cartogram that scales the size of the constituencies to to the total number of eligible voters in 2019.
```{r cartograms, include=TRUE}
# Plot the number of electorates against the size of the constituencies in a scatterplot
plot(data$electorates, st_area(data, byid = TRUE))
# Here we get an idea of the number of eligible voters against the size of the constituencies. The y-axis displays the area of the constituency, while the x-axis displays the total number of electorates. There is a lot of variation when it comes to the size and number of electorates in the constituencies, and this is what we hope to reduce with cartograms.

# Using the cartogram_cont() function we create the cartogram that scales the area of the constituencies to the total number of eligible voters in 2019. 
cartogram_electorates_2019 <- cartogram_cont(data, "electorates")
# Now the sizes of the constituencies correspond to the number of eligible voters. 

# Once again we plot the number of electorates against the size of the constituencies in a scatteplot, but this time we use the cartogram to see whether the variation has been reduced.
plot(cartogram_electorates_2019$electorates, st_area(cartogram_electorates_2019, byid = TRUE))
# We can see that the relationship between the size of the constituencies and the number of electorates has become much more linear because we have scaled the area to the number of voters. Hence, adjusting the size of the constituencies to correspond to the number of votes makes the relationship much more linear. 
# The cartogram_cont() makes simulations which is why there is still some variation left.

# Plot the cartogram
plot(cartogram_electorates_2019$geometry, 
     col = "grey",
     main = "Cartogram: Constituency Area Scaled to Number of Electorates in 2019", main.title.size = 0.9)
```

__CARTOGRAM 2:__ SCALING CONSTITUENCIY AREA TO PERCENTAGE OF *CONSERVATIVE* VOTES IN 2019 
Now we focus on the percentage of Conservative votes in the 2019 election. We create a cartogram that scales the size of the constituencies to the percentage of Conservative votes.
```{r cartogram Conservative, include=TRUE}
# First we inspect the relationship between the size of the constituencies and the percentage of Conservative votes
plot(data$perc_votes_conservative, st_area(data, byid = TRUE))

# Using the cartogram_cont() function we create the cartogram that scales the area of the constituencies to the percentage of Conservative votes in 2019. 
cartogram_conservative_2019 <- cartogram_cont(data, "perc_votes_conservative")

# Once again we plot the percentage of Conservative votes aginst the size of the constituencies in a scatteplot, but this time we use the cartogram to see whether the variation has been reduced.
plot(cartogram_conservative_2019$perc_votes_conservative, st_area(cartogram_conservative_2019, byid = TRUE))

# Plot the cartogram
plot(cartogram_conservative_2019$geometry, 
     col = "blue",
     main = "Cartogram: Constituency Area Scaled to Percentage of Conservative Votes in 2019", main.title.size = 0.9)
```

__CARTOGRAM 3:__ SCALING CONSTITUENCIY AREA TO THE PERCENTAGE OF *LABOUR* VOTES IN 2019
Now we focus on the percentage of Labour votes in the 2019 election. We create a cartogram that scales the size of the constituencies to the percentage of labour votes.
```{r cartogram, Labour, include=TRUE}
# First we inspect the relationship between the size of the constituencies and the percentage of Labour votes
plot(data$perc_votes_labour, st_area(data, byid = TRUE))

# Using the cartogram_cont() function we create the cartogram that scales the area of the constituencies to the percentage of Labour votes in 2019. 
cartogram_labour_2019 <- cartogram_cont(data, "perc_votes_labour")

# Once again we plot the percentage of Labour votes aginst the size of the constituencies in a scatteplot, but this time we use the cartogram to see whether the variation has been reduced.
plot(cartogram_labour_2019$perc_votes_labour, st_area(cartogram_labour_2019, byid = TRUE))

# Plot the cartogram
plot(labour_voters_2019$geometry, 
     col = "red",
     main = "Cartogram: Constituency Area Scaled to Percentage of Labour Votes in 2019", main.title.size = 0.9)
```

__CONCLUSION:__
Based on the cartograms it seems that spatial autocorrelation is present. To assess exactly how much spatial dependency is present, we can perform a test for spatial autocorrelation.


-------- ## __SPATIAL AUTOCORRELATION TEST__ ## --------

When we assess the cartograms for Conservative vote share and Labour vote share in 2019, it is clear that there is a tendency for urban constituencies, in particular constituencies near London, Liverpool, and Manchester, to favor the Labour party while more rural constituencies tend to favor the Conservative party. Hence, it seems like constituencies close to the cities tends to have similar voting preferences while constituencies further away from the city also tend to vote similarly. 
We want to test for how much spatial correlation is actually present, and we do this with a spatial autocorrelation test. In other words, we want to test whether it is more likely that constituencies that share borders would have similar voting preferences compared to randomly selected constituencies. 

Before we can test for spatial autocorrelation, we need to define the neighboring constituencies. We have chosen to utilize different kinds of neighborhood definitions in order to see how constitent the results are. First we define the neighboring constituencies according to adjacency, i.e. constituencies with shared borders are considered to be neighbors. This is also known as the "Queen Adjacency" neighborhood definition.

__Defining neighboring constituencies according to *adjacency*__
```{r, neigborhood definition, include=TRUE}
# First, we simplify the constituency boundaries to speed up processing. The st_simplify() function changes the data to "geometry" and therefore we use the st_cast() function to transform it back to "polygons"
constituencies_sm <- st_cast(st_simplify(data, dTolerance = 250), to = "MULTIPOLYGON")

# Plot the simplified geometry to make sure it looks decent
plot(constituencies_sm$geometry)

# Now we define the neighboring constituencies using the poly2nb() function which defines the neigbors according to adjacency (shared borders)
adjacency_neighbors <- poly2nb(constituencies_sm$geometry)
# Now we have a list of all neighboring constituencies. We can see that there are x regions with no neighbors (these are the islands). This might have some implications for the weighted matrix we make later and consequently Moran's I.

# Now we extract the center points of each constituency
constituency_centers <- st_coordinates(st_centroid(constituencies_sm$geometry))

# Now we plot the neighboring constituencies. 
plot(constituencies_sm$geometry); plot(adjacency_neighbors, constituency_centers, col = "red",add = TRUE)
# Here we can see the neighborhoods. Only polygons that have shared borders have neigbors, because we are using the adjacency definiton of neighborhood.
```

Now that we have defined the neigboring constituencies according to the adjacency criterion, we can test for spatial autocorrelation by computing the Moran's I statistic. With Moran's I we are checking whether neigboring constituencies are more correlated in terms of voting preferences compared to a random distribution of constituencies. 

__MORAN'S I: THE CONSERVATIVE PARTY__
Below we are computing Moran's I for the percentage of Conservative votes in 2019 to see exactly how much spatial autocorrelation is present. 
```{r Moran's I Conservative, include=TRUE}
# Since we cannot trust the p-value using the moran.test() function, we run a Monte Carlo simulation that provides a more trustworthy p-value. When performing a Monte Carlo simulation, we are randomly distributing the values for 999 simulations which is why the p-value becomes more reliable. 
moran.mc(cartogram_conservative_2019$perc_votes_conservative,
         nb2listw(adjacency_neighbors, zero.policy=TRUE), # nb2listw creates a weighted list of neighbors.
         zero.policy=TRUE, # zero.policy ensures that constituencies with missing neigbors are replaced with 0
         nsim = 999)
```

__MORAN'S I: THE LABOUR PARTY__
Below we are computing Moran's I for the percentage of Labour votes in 2019 to see exactly how much spatial autocorrelation is present. 
```{r Moran's I Labour, include=TRUE}
# Compute Moran's I for Labour votes using Monte Carlo simulation
moran.mc(cartogram_labour_2019$perc_votes_labour,
         nb2listw(adjacency_neighbors, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)
```

__CONCLUSION:__ 
For both the Conservative and Labour votes, there are clear signs of spatial autocorrelation, which means that neigboring constituencies seem to display similar voting preferences, and hence it is more likely that two neighboring constituencies voted for the same party compared to two randomly selected constituencies. This is demonstrated by the fact that Moran's I is positive and the p-value is signicant, which means that we can reject the null hypothesis stating that the results are derived from a random distribution. This means that there is a very low probability (< 0.05) that the results obtained are random, which means that spatial autocorrelation is present.

Now let's see if these results are consistent when using another neigborhood definition such as the K-nearest neigborhood definition. Below we use different distances to define neighboring constituencies. 

__Defining neighboring constituencies according to *K-nearest neighbors*__
```{r neighborhood definition, include=TRUE}
# First we extract the center points of each constituency
constituency_centers <- st_centroid(constituencies_sm$geometry, of_largest_polygon = TRUE)

# Now we create a list of neighbors based on 50 km. distance. Hence, neigbors within 50 km. of each other are to be considered neighbors
neighbors_50km <- dnearneigh(constituency_centers, 0, 50000)

# Plot neighbors with 50 km. distance definition
plot(constituencies_sm$geometry); plot(neighbors_50km, constituency_centers, col = "red", add = TRUE)
title(main = "Neighboring Constituencies within 50 km. distance") # plot title

# Now we create a list of neighbors based on 20 km. distance. Hence, neigbors within 20 km. of each other are to be considered neighbors
neighbors_20km <- dnearneigh(constituency_centers, 0, 20000)

# Plot neighbors with 20 km. distance definition
plot(constituencies_sm$geometry); plot(neighbors_20km, constituency_centers, col = "red", add = TRUE)
title(main = "Neighboring Constituencies within 20 km. distance") # plot title

# Make neighbor list from 3 nearest neighbours
coords <- coordinates(as(constituencies_sm, "Spatial")) # convert to spatial object  and extract coordinates
col.knn <- knearneigh(coords, k=3) # define the 3 nearest neighbors based on the coordiantes 
plot(st_geometry(constituencies_sm), border="grey") # plot
plot(knn2nb(col.knn), coords, add=TRUE)
title(main="K nearest neighbours, k = 3")
```

Now that we have defined the neigboring constituencies according to K-nearest neighbors definition, we can test for spatial autocorrelation by computing the Moran's I, and see whether we still find significant spatial autocorrelation.  
__MORAN'S I: THE CONSERVATIVE PARTY__
```{r Moran's I Conservative, include=TRUE}
# Run Moran's I test using Monte Carlo simultion Conservative vote share in 2019 with nearest neighbor definition of 50 km. distance
moran.mc(cartogram_conservative_2019$perc_votes_conservative,
         nb2listw(neighbors_50km, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)

# Run Moran's I test using Monte Carlo simultion Conservative vote share in 2019 with nearest neighbor definition of 20 km. distance
moran.mc(cartogram_conservative_2019$perc_votes_conservative,
         nb2listw(neighbors_20km, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)

# Run a Moran I test with Monte Carlo simultion on number of votes for conservatives in percentage in 2019 based on 3 neighbours
moran.mc(cartogram_conservative_2019$perc_votes_conservative,
         nb2listw(knn2nb(col.knn), zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)
```

__MORAN'S I: THE LABOUR PARTY__
```{r Moran's I Labour, include=TRUE}
# Run Moran's I test using Monte Carlo simultion Labour vote share in 2019 with nearest neighbor definition of 50 km. distance
moran.mc(cartogram_labour_2019$perc_votes_labour,
         nb2listw(neighbors_50km, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)

# Run Moran's I test using Monte Carlo simultion Labour vote share in 2019 with nearest neighbor definition of 20 km. distance
moran.mc(cartogram_labour_2019$perc_votes_labour,
         nb2listw(neighbors_20km, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)

# Run a Moran I test with Monte Carlo simultion on number of votes for Labour in percentage in 2019 based on 3 neighbours
moran.mc(cartogram_labour_2019$perc_votes_labour,
         nb2listw(knn2nb(col.knn), zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)
```

__CONCLUSION:__
Even when defining neighbors according to the K-nearest neighbors definition, we find that spatial autocorrelation is still present, which is indicated by the positive Moran's I and the significant p-values. Taken together this means that it seems that neigboring constituencies tend to display similar voting preferences.


-------- ## __ADDRESSING THE MAUP PROBLEM__ ## --------

The way in which spatial boundaries are drawn will inevitably affect the results of the statistical analyses we conduct. The results obtained using one type of aggregation scheme are most likely not going to be identical to the results obtained using another type of aggregation scheme. The problem associated with analyzing aggregated data is referred to as the “Modifiable Areal Unit Problem” (MAUP).
Given that we are using aggregated data, it was deemed necessary to address this exact problem. To see whether different kinds of aggregation schemes have an effect on the results we obtain, we are going to combine constituencies into counties and see whether this affects the results of the spatial autocorrelation test. One might suspect that using a different kind of aggregation scheme would potentially reveal a different degree of spatial autocorrelation, hence, this is what we are going to investigate in the following. 

__AGGREGATING CONSTITUENCIES INTO COUNTIES__
Below we are aggregating the constituencies and their associated data. This means that constituencies belonging to the same county will be aggregated.

```{r aggregating constituencies, include=TRUE}
# To not aggregate unneccessary data, we select the relevant columns
data_filtered <- data %>% 
  select(perc_votes_conservative, perc_votes_labour, county)

# Aggregating constituencies into counties using the aggregate() function. This means that we combine the constituencies based on the county they belong to, and we take the average of each of their column values. 
aggregated_constituencies_counties <- aggregate(data_filtered,
                                       by = list(data_filtered$county),
                                       FUN = mean,
                                       do_union = TRUE,
                                       simplify = TRUE,
                                       join = st_intersects,
                                       dissolve = TRUE
)

# Simplify the boundaries to speed up the processing
aggregated_constituencies_counties_sm <- st_simplify(aggregated_constituencies_counties, preserveTopology = TRUE, dTolerance = .07)

# Plot the aggregated data
plot(aggregated_constituencies_counties_sm$geometry)
```




```{r aggregating constituencies, include=TRUE}
# We start by creating a new dataframe and sort by latitude and longitude in order to get the constituencies listed according to their locations
constituencies_sorted <- election_per_constituency[order(election_per_constituency$long, election_per_constituency$lat),]

# To aggregate neighboring constituencies we need to assign them identical IDs to aggregate by. We create a new column called "aggregation_ID" and we assign every two constituencies the same ID. 
constituencies_sorted$aggregation_ID <- rep(c(1:266), each = 2)

# Next we select only the columns in the dataframe that we are interested in
constituencies_sorted <- constituencies_sorted %>% 
  select(long, lat, aggregation_ID, perc_votes_conservative, perc_votes_labour)

# Now we can aggregate the constituencies by their aggregation ID using the aggregate() function. This means that we combine the constituencies with the same aggregation ID and we take the average of each of their column values. 
aggregated_constituencies <- aggregate(constituencies_sorted,
                                       by = list(constituencies_sorted$aggregation_ID),
                                       FUN = mean,
                                       do_union = TRUE,
                                       simplify = TRUE,
                                       join = st_intersects,
                                       dissolve = TRUE
)

# Plot the aggregated data. We simplify the geometry to speed up the plotting.
plot(st_geometry(st_simplify(aggregated_constituencies, preserveTopology = TRUE, dTolerance = .07)), col = "grey")
```

Now that we have aggregated the constituencies, we can redefine the neighborhoods. We once again use the adjacency neighborhood definition. 

__Redefining Neighboring Constituencies for Aggregated Data__
```{r neighborhood definition, include=TRUE}
# Transform the CRS of the data to 277700 which is the CRS of England
aggregated_constituencies <- st_transform(aggregated_constituencies_counties, crs = 27700)

# Simplify the boundaries to speed up the processing
constituencies_aggregated_sm <- st_simplify(aggregated_constituencies, preserveTopology = TRUE, dTolerance = .07)

# Plot the simplified geometry to make sure it looks decent
plot(constituencies_aggregated_sm$geometry)

# Now we define the neighboring constituencies using the poly2nb() function which defines the neigbors according to adjacency (shared borders).
neighbors_aggregated_constituencies <- poly2nb(constituencies_aggregated_sm$geometry)
# Now we have a list of all neighboring constituencies. 

# Now we extract the center points of each constituency
aggregated_constituencies_centers <- st_coordinates(st_centroid(constituencies_aggregated_sm$geometry))

# Now we plot the neighboring constituencies. 
plot(constituencies_sm$geometry); plot(neighbors_aggregated_constituencies, aggregated_constituencies_centers, col = "red", add = TRUE)
# Here we can see the neighborhoods. Only polygons that have shared borders have neigbors, because we are using the adjacency definiton of neighborhood.
```

Now that we have defined the new neighborhoods for the aggregated constituencies, we can compute Moran's I to test for spatial autocorrelation with this new aggregation scheme. 

__MORAN'S I: THE CONSERVATIVE PARTY__
```{r Moran's I Conservative, include=TRUE}
# Compute Moran's I for the Conservative party vote share
moran.mc(as.numeric(constituencies_aggregated_sm$perc_votes_conservative),
         nb2listw(nb_aggregated, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)
```

__MORAN'S I: THE LABOUR PARTY__
```{r Moran's I Labour, include=TRUE}
# Compute Moran's I for the Labour party vote share
moran.mc(df_aggregated$perc_votes_labour,
         nb2listw(nb_aggregated, zero.policy=TRUE),
         zero.policy=TRUE, 
         nsim = 999)
```

__CONCLUSION:__
It is now clear that even with a different aggregation scheme, spatial autocorrelation is still present. Hence, even when the constituency borders are changed, it still seems that neighboring constituencies tend to display similar voting behavior. 

Now we have concluded the spatial analysis of the 2019 UK election data. We continue with a spatial regression analsyis which can be found in the ```Regression_Analysis.Rmd``` script provided in the data folder of the repository.